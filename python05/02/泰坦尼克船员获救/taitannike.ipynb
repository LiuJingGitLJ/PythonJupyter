{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas #ipython notebook\n",
    "titanic = pandas.read_csv(\"titanic_train.csv\")\n",
    "titanic.head(5)\n",
    "#print (titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "# print(titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(titanic[\"Sex\"].unique())\n",
    "\n",
    "# Replace all the occurences of male with the number 0.\n",
    "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(titanic[\"Embarked\"].unique())\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna('S')\n",
    "titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the linear regression class\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Sklearn also has a helper that makes it easy to do cross validation\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# The columns we'll use to predict the target\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm class\n",
    "alg = LinearRegression()\n",
    "# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.\n",
    "# We set random_state to ensure we get the same splits every time we run this.\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n",
    "    train_predictors = (titanic[predictors].iloc[train,:])\n",
    "    # The target we're using to train the algorithm.\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    # Training the algorithm using the predictors and target.\n",
    "    alg.fit(train_predictors, train_target)\n",
    "    # We can now make predictions on the test fold\n",
    "    test_predictions = alg.predict(titanic[predictors].iloc[test,:])\n",
    "    predictions.append(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.99877810e-02  9.60756206e-01  5.92676278e-01  9.31138728e-01\n",
      "  5.29343071e-02  1.70275685e-01  3.69943590e-01  1.03474847e-01\n",
      "  5.21597906e-01  8.74491050e-01  6.48883611e-01  8.29742769e-01\n",
      "  1.34797198e-01 -1.61126844e-01  6.58141307e-01  6.39819748e-01\n",
      "  1.51733875e-01  2.95432718e-01  5.35377959e-01  6.21007683e-01\n",
      "  2.61872592e-01  2.62687561e-01  7.31739160e-01  5.05995897e-01\n",
      "  5.61398567e-01  3.35039734e-01  1.30338808e-01  4.68765767e-01\n",
      "  6.60737753e-01  9.10819218e-02  4.77223920e-01  1.04220026e+00\n",
      "  6.60691613e-01  8.71539273e-02  5.28550732e-01  4.01874338e-01\n",
      "  1.30340307e-01  1.29339672e-01  5.72717129e-01  6.65238822e-01\n",
      "  4.83215779e-01  7.60807408e-01  1.30578363e-01  8.71867121e-01\n",
      "  7.09855487e-01  9.11369897e-02  1.39181745e-01  6.60691613e-01\n",
      "  6.82833485e-02  6.06254374e-01  4.92254383e-02  1.29250392e-01\n",
      "  9.02668258e-01  7.51677954e-01  3.19636822e-01  5.05995897e-01\n",
      "  8.23411477e-01  1.27611544e-01  8.16516947e-01 -3.70209060e-02\n",
      "  1.63085464e-01  9.57981340e-01  3.96742103e-01  6.16138409e-02\n",
      "  5.42714233e-01  6.62112275e-02  7.79751268e-01  1.40293401e-01\n",
      "  4.40592742e-01  3.50534388e-02  2.72709814e-01  4.26360339e-01\n",
      "  3.55241143e-01  1.10226880e-01  8.66078358e-02  1.07366720e-01\n",
      "  9.10819218e-02  9.11369897e-02  3.82661024e-01  5.72471068e-01\n",
      "  1.24221410e-01  8.61972872e-02  6.60705005e-01  5.10138486e-01\n",
      "  8.45241581e-01  4.56477760e-01  3.22699204e-02  9.11369897e-02\n",
      "  9.37604538e-01  1.12967094e-01  8.56794636e-02  1.34727274e-01\n",
      "  3.83320807e-01  6.14970393e-03 -7.83320148e-02  9.11369897e-02\n",
      "  3.10516665e-01  5.49345421e-01  7.23544338e-01  2.33721448e-01\n",
      "  5.81750798e-01  9.10819218e-02  5.25738424e-01  6.40651310e-02\n",
      " -2.52427240e-02  9.10819218e-02  6.19865700e-01  9.10387818e-02\n",
      "  3.65066610e-02  6.32939707e-01  4.08195377e-01  6.63657306e-01\n",
      "  1.23882146e-01  5.92491292e-01  6.83623624e-01  1.29295032e-01\n",
      " -6.19221217e-02  2.59223480e-01  6.09655955e-01  5.30794378e-01\n",
      "  2.88023805e-01  9.11369897e-02  2.82857942e-01  7.61542726e-01\n",
      "  3.45640063e-01  1.85484998e-01  1.70022737e-01  1.12642722e-01\n",
      "  5.59420117e-01 -2.02485747e-03  1.03290733e-01  1.34440079e-01\n",
      "  4.46807623e-01  7.51677954e-01  3.11805296e-01  3.62947385e-01\n",
      "  9.75724449e-01  4.29554800e-01  1.57043954e-01  5.82928575e-01\n",
      "  5.57105476e-01  6.14443886e-01  5.72812834e-01  2.18783352e-01\n",
      "  3.49472299e-01  2.86040080e-01  9.65037360e-02  5.60916106e-01\n",
      "  1.86919710e-01  2.19027353e-01  1.69739986e-01  1.00690768e+00\n",
      " -5.89449777e-02 -4.15452572e-02  9.08736139e-02  3.95827915e-01\n",
      "  7.26175962e-01  8.02219375e-02  9.13557255e-02 -2.22536096e-01\n",
      " -2.66919104e-02  7.21593360e-01  1.01953834e-01  1.51388512e-01\n",
      "  8.19705948e-02  1.32518461e-01  9.70245311e-01  3.28974893e-01\n",
      "  5.02576476e-01  1.08437940e-01  3.25183297e-01  1.40818823e-01\n",
      "  6.63268211e-01  1.29295032e-01  3.90965934e-01  7.86503606e-02\n",
      " -3.68524682e-02  9.13671691e-01  2.84517666e-01  4.46019673e-02\n",
      "  2.68132779e-01  3.35661255e-01  1.96299597e-03  3.51470400e-01\n",
      "  6.51010647e-01  5.11174133e-01  6.29850621e-01  4.10021732e-01\n",
      "  4.03081359e-02  4.74217131e-02  7.64271489e-01  3.44550453e-01\n",
      "  5.97245007e-01  3.69521460e-01  9.46062691e-01  9.12083149e-01\n",
      "  1.70022737e-01 -1.85251802e-02  6.60691613e-01  8.07931698e-01\n",
      "  9.16548133e-02 -2.22536096e-01  5.78367977e-02  3.48321010e-02\n",
      "  1.45712251e-01  6.91179799e-01  3.84837497e-02  1.45383056e-01\n",
      "  7.26181926e-01  4.78394987e-01  1.12609974e-01  7.50755869e-01\n",
      "  1.23596450e-01  2.84517666e-01  1.36414068e-01  1.01395495e+00\n",
      "  5.87218752e-01  1.90418359e-01  1.02889863e+00  2.83624866e-01\n",
      "  1.56627303e-01  3.00890244e-01 -3.43861103e-02  9.10819218e-02\n",
      "  4.37274991e-01  1.24346402e-01  3.43657653e-01  1.31782740e-01\n",
      "  3.50007979e-01  4.53816408e-01  9.41986239e-01  8.55812557e-02\n",
      "  1.26427969e-01  5.14461976e-01  3.16370023e-01  5.81627306e-01\n",
      "  1.79146187e-01  8.33217359e-01  3.43657653e-01  2.67886176e-01\n",
      "  5.89980704e-01  6.29850621e-01  2.89082393e-01  1.23551810e-01\n",
      "  1.19423755e-01  4.49914049e-01  5.98080236e-01  7.41700785e-01\n",
      "  3.95976588e-01  1.24570927e-01  9.08512939e-02  5.10217925e-01\n",
      "  3.17243789e-01  4.94880818e-02  4.48434902e-01  5.51647950e-01\n",
      "  1.05176735e+00  1.00396283e+00  1.16824364e+00  6.37295280e-01\n",
      "  1.70022737e-01  3.47081525e-02  3.23790141e-01  4.27827834e-01\n",
      "  6.60691613e-01  2.50879710e-01  1.07703504e-04  7.38026906e-02\n",
      "  8.41682429e-01  9.94221666e-01  5.04388858e-01  1.04634754e-01\n",
      "  6.84091736e-01  4.60920013e-01  6.60691613e-01  7.87205387e-01\n",
      "  4.88920786e-01  2.90790162e-01  1.24446245e-01  4.80968077e-01\n",
      " -3.19057282e-02  9.10670657e-02  1.57145126e-01  1.40254724e-01\n",
      "  5.02603260e-01  1.03564537e-01  8.07397611e-02  1.23827078e-01\n",
      "  2.19027353e-01  6.93436769e-01  1.02306096e+00  1.07151871e+00\n",
      "  2.91224311e-01  6.03921666e-01  1.12912026e-01  5.42714233e-01\n",
      "  1.54899175e-01  1.13774791e+00  4.41732120e-01  9.85513466e-01\n",
      "  6.69153707e-01  8.25422792e-02  1.51426237e-01  8.36420139e-01\n",
      "  9.70452598e-02  6.47114810e-01  1.03845173e+00  1.06064212e+00\n",
      "  2.46478416e-01  9.83649024e-01  1.04411609e+00  1.10195734e+00\n",
      "  7.25963867e-01  9.69270903e-02  1.13884110e-01  6.08249871e-01\n",
      "  7.49057247e-01  9.04240008e-02  1.00314273e+00  9.15883676e-01\n",
      "  1.36798861e-01  1.03654869e-01  8.22964581e-01  7.55174001e-01\n",
      " -2.77462854e-01  1.00359640e+00 -1.26360431e-01  7.08656783e-01\n",
      "  5.24387994e-01  1.06900476e+00  5.80441382e-01  3.22463312e-01\n",
      "  4.59047511e-01  8.48130973e-02  9.68383833e-01  9.69270903e-02\n",
      "  4.12373899e-01  9.69089012e-01 -1.73269800e-02  3.31191577e-01\n",
      "  3.89531457e-01  9.74554712e-01  2.64579911e-01  2.84763247e-01\n",
      "  2.10757680e-01  7.89390128e-01  6.81745667e-01  5.50818102e-01\n",
      "  2.11322379e-01  3.32573926e-03  1.31584603e-01  4.45180647e-01\n",
      "  1.61163882e-01  7.44051125e-02  1.33632653e-01  9.81564518e-02\n",
      "  9.89135387e-01  6.95201225e-01  6.69252718e-01  6.69252718e-01\n",
      " -5.73228314e-02  2.56057591e-01  5.13061714e-01  4.91844688e-02\n",
      "  1.26898442e-01  8.29766307e-02  7.45560317e-01  6.31534974e-01\n",
      "  6.69153707e-01  1.03349593e+00  4.67953593e-01  1.12836711e-01\n",
      "  1.57595269e-01  5.99886200e-01  6.12596703e-01  9.66152920e-01\n",
      "  6.34697964e-01  6.05111298e-01  1.84993018e-01  1.57384526e-01\n",
      "  1.03364995e+00  8.00432821e-01  7.00383521e-02  8.58717774e-01\n",
      "  9.69270903e-02  3.78221229e-01  3.77154650e-02  7.08656783e-01\n",
      "  1.71238664e-01  8.72937864e-01  3.86926324e-01  1.43944908e-01\n",
      " -3.64111727e-03  1.02362819e+00  6.09208668e-01  1.37217129e-01\n",
      "  5.74610977e-01  1.53442303e-01  2.96302956e-01  7.62210794e-01\n",
      "  2.29439004e-02  1.10500817e-01  5.93103774e-01  5.27274143e-02\n",
      "  6.49235976e-01  1.80048660e-01 -5.79235547e-02  3.77247718e-01\n",
      "  1.43928968e-01  4.47767765e-01  9.69270903e-02  1.70571259e-01\n",
      "  9.75733473e-01  2.54617499e-01 -1.06949936e-02  5.94944362e-01\n",
      "  6.77122843e-01  8.10481157e-01  2.51124353e-01  7.09106800e-01\n",
      "  1.34146713e-01  2.18336258e-01  9.01833716e-02  5.39877502e-01\n",
      "  1.13710536e-01  9.64321883e-02  7.22146132e-01  8.32991434e-01\n",
      "  1.71254604e-01  7.01341446e-02  4.38705080e-01  5.50818102e-01\n",
      "  6.27957229e-01  1.70341963e-01  2.62890713e-01  1.03283656e+00\n",
      "  5.42346468e-01  6.64292528e-01  2.88859398e-01  2.42480726e-01\n",
      "  5.98327655e-01  1.51978682e-01  6.67225606e-02  7.62479013e-01\n",
      "  9.70931560e-02  6.23281053e-01  8.58739079e-01  3.98338407e-01\n",
      "  6.85263852e-01  2.80265429e-01  1.52490249e-01  5.58822035e-02\n",
      "  4.63388752e-01  3.32283800e-01  9.70452598e-02  1.27418935e-01\n",
      "  1.89777264e-01  9.05706854e-01  6.12552031e-01  1.71254604e-01\n",
      "  3.04149503e-01  5.66785869e-02  3.20035037e-01  1.30024334e-01\n",
      "  9.70452598e-02  2.90011323e-02  2.54617499e-01  2.50327273e-01\n",
      "  1.71235446e-01  7.13856912e-01  9.64321883e-02  3.02368545e-02\n",
      "  6.70572687e-01  8.33944241e-01  6.36680867e-01  4.58208416e-01\n",
      "  1.80048660e-01  3.92526307e-02  1.37006386e-01  7.63476152e-01\n",
      " -1.61067656e-02  2.54617499e-01 -5.09658741e-02  3.60650350e-01\n",
      "  4.95264011e-01  4.47767765e-01  8.87838669e-01  2.76505307e-01\n",
      "  8.35897022e-02  1.70955707e-01  5.58822035e-02  1.43526640e-01\n",
      "  2.60082092e-01  2.04220920e-01  1.44139712e-01  1.39175815e-01\n",
      "  7.88238805e-01  1.02447952e-01  9.83008999e-01  1.23761572e-01\n",
      "  1.71520210e-01  7.16248158e-01  6.69061133e-01  5.35572600e-01\n",
      "  1.06327957e+00  5.56015243e-01  7.19526886e-01  4.38705080e-01\n",
      "  1.08138022e-01  1.47626740e-01  1.64526825e-01  9.70452598e-02\n",
      "  3.84681685e-01  7.73780511e-01  1.23531670e-01  3.16602450e-01\n",
      "  7.20196492e-01  1.83822569e-01  6.68323902e-01  7.00159750e-02\n",
      "  9.74455043e-01  1.37293763e-01  1.33632653e-01  8.80626954e-01\n",
      "  1.33635872e-01  8.71573690e-02  6.12552031e-01  5.88316896e-01\n",
      "  2.29439004e-02  1.86840889e-01  8.87430559e-01  1.33635872e-01\n",
      "  1.47708324e-01  6.23853354e-01  5.81958187e-01  8.94640720e-01\n",
      "  3.24332840e-01  1.02157960e+00  1.01988149e-01  1.01250232e+00\n",
      "  8.97570091e-01  5.20113577e-01  5.06658019e-01  1.97335914e-01\n",
      "  3.38829631e-01  1.96083556e-01  7.82696141e-01  3.02460501e-01\n",
      "  1.30333344e-02  3.57402932e-01  5.95282551e-01  2.81270101e-01\n",
      "  1.71315298e-01  1.73999326e-01  6.35100292e-01  2.09960600e-01\n",
      "  7.98973665e-01  6.29939751e-01  8.43358119e-01  4.97992112e-01\n",
      "  1.71254604e-01  1.61937445e-02  2.64963080e-01  9.70452598e-02\n",
      "  5.94944362e-01  3.57038537e-02  1.57477100e-01  5.59646864e-01\n",
      "  1.33635872e-01  6.99840953e-02  3.39195826e-02  6.86923354e-01\n",
      "  3.84758319e-01  6.69153707e-01  1.77778606e-01  1.62538158e-01\n",
      "  7.22112340e-01  8.34795382e-01  5.86779625e-01  7.00383521e-02\n",
      "  7.35757004e-01  9.04513049e-01  9.96200729e-02  4.32505529e-01\n",
      "  1.34772583e-01  1.02529894e+00  1.38284792e-01  2.41050432e-01\n",
      "  1.37411933e-01  9.70452598e-02  4.92419442e-02  8.01694363e-01\n",
      " -3.13956091e-02  6.49878062e-01  1.72889219e-01  1.70294715e-02\n",
      "  7.82616935e-01 -8.34788848e-03  1.47022266e-01  3.10888595e-01\n",
      "  7.28261340e-01  1.01479914e-01  4.24565622e-01  1.57316587e-02\n",
      "  4.37708069e-01  1.44204264e-02  9.07678482e-02  4.33913871e-01\n",
      "  8.26537251e-01  8.45262338e-01  5.42776171e-01  1.01763663e-01\n",
      "  6.70148479e-01  1.92163452e-01  6.39359534e-02  7.62650655e-01\n",
      "  3.10124701e-02  5.90024631e-01  8.31356231e-01  2.78648916e-01\n",
      "  1.08309653e-01  3.04531238e-01  1.50864127e-01  1.38986099e-01\n",
      "  1.36219795e-01  2.51197915e-01  2.02625887e-01  9.72357134e-01\n",
      "  1.12191979e-01  1.92169054e-01  1.50211875e-01 -2.14264992e-02\n",
      "  4.52451020e-01  4.38789988e-01  6.04820088e-01  7.89326541e-01\n",
      "  8.00459867e-02  2.10435721e-01  5.70885269e-01  5.70841743e-02\n",
      "  1.44342132e-01  1.00451104e+00  6.42312317e-01  8.51755703e-02\n",
      "  7.33373007e-01  3.09602117e-01  1.49684208e-01  3.22228832e-01\n",
      "  1.01595923e-01  6.50604478e-01  1.01479914e-01  8.45026241e-01\n",
      "  1.38791822e-01  7.14365273e-01  7.68287651e-01  1.84938938e-01\n",
      "  1.01479914e-01  6.54218524e-01  2.93878313e-01  2.96413137e-01\n",
      "  1.92833539e-01  8.27498735e-02  3.28441263e-01  5.87658439e-02\n",
      "  1.02674988e-01  1.42090676e-01  2.83166248e-01  1.01520440e-01\n",
      "  2.10876914e-02  9.01930011e-01  6.80182444e-01  3.63633521e-01\n",
      "  4.29834748e-02  2.51030051e-01  2.71459394e-01  1.55080767e-01\n",
      "  1.20174297e-01  6.76615822e-01  5.21604336e-01  2.74876851e-01\n",
      "  7.14261845e-01  4.63722197e-01  1.43882255e-01 -3.38493769e-02\n",
      "  5.08333972e-02  2.88240761e-01  4.71949096e-03  1.48920991e-01\n",
      "  1.55073789e-01  9.65241409e-01  3.61956120e-01  8.01212426e-01\n",
      "  8.51755703e-02  1.63090365e-01  2.58489938e-01  1.38385623e-01\n",
      "  1.57316587e-02  7.14397446e-01  2.98282232e-01  2.65779163e-02\n",
      "  9.41922468e-01  3.92478820e-01  7.25879907e-01  2.08234335e-01\n",
      "  7.05625434e-02  2.03820545e-01  6.98106244e-01  3.54986591e-01\n",
      "  9.42312534e-01  1.08182230e-01  1.01115214e+00  4.29882986e-01\n",
      "  2.72580965e-01  9.55913060e-02  1.38553363e-01  1.49766670e-01\n",
      "  8.76445205e-01  7.95521275e-01  1.89563479e-01  7.47402760e-02\n",
      "  9.05943831e-01  1.19035222e-01  2.34961953e-01  1.49265429e-01\n",
      "  3.84688624e-01  1.44070963e-01  6.51000458e-01  7.14396037e-01\n",
      "  2.37161612e-01  5.98123216e-01  8.84762775e-01  2.34195832e-01\n",
      "  2.71459394e-01  2.93878313e-01  2.93878313e-01  9.60495497e-02\n",
      "  4.82543535e-01  2.74738708e-01  1.01479914e-01  1.01479914e-01\n",
      "  4.28725578e-01  3.27845711e-01  8.83507841e-01  7.85083053e-02\n",
      "  8.54020195e-02  1.53868294e-01  1.25458500e-01  7.78614476e-01\n",
      "  4.27536886e-01  1.76095354e-01  8.78367308e-01  2.23270579e-01\n",
      "  7.41615725e-02  1.28260077e-01  6.34105869e-01  3.76826088e-01\n",
      "  1.01513462e-01  3.21161697e-01  6.92919862e-02  9.05219168e-01\n",
      "  9.92643346e-02  3.21100762e-02  1.89869119e-01  8.47257439e-01\n",
      "  1.65792833e-01  7.70032759e-01  4.70822280e-01  7.01001762e-01\n",
      "  1.45018183e-01  7.98992141e-02  1.22365867e-01 -5.62678525e-03\n",
      "  6.34840292e-01  1.47022266e-01  6.21554022e-01  1.55089154e-01\n",
      "  1.92163452e-01  7.45360827e-01  1.92167645e-01  8.15272492e-01\n",
      "  7.49589740e-01  9.59168970e-01  4.23369546e-01  6.56067455e-02\n",
      "  1.17831761e-01  1.17764665e-01  6.77402825e-01  1.31033823e-01\n",
      "  2.11184136e-01  3.61128670e-01  1.92163452e-01  3.27009298e-01\n",
      "  2.80865752e-01  4.73809464e-01  1.17548012e-01  2.08181789e-01\n",
      "  8.39842956e-01  6.07376016e-01  1.36308792e-01  5.71394060e-01\n",
      "  2.34961953e-01  7.32664113e-01  4.58929866e-01  2.99802486e-01\n",
      "  1.07144857e-01  8.54523415e-02  3.79873628e-01  6.77309159e-01\n",
      "  2.08181789e-01  8.74780819e-01  1.12194764e-01  3.71105893e-02\n",
      "  2.30444621e-01  5.78112549e-01  8.80381008e-02  4.38789988e-01\n",
      "  6.50478673e-01  2.52145211e-01  2.16244600e-02  7.72356638e-02\n",
      "  7.64956968e-01  1.06578734e-01  3.85229660e-01  6.33022282e-01\n",
      "  6.89918839e-02  1.92431836e-01  8.51755703e-02  4.59963761e-01\n",
      "  1.92163452e-01  7.52074841e-01  6.94810438e-01  3.74543331e-01\n",
      "  1.47020857e-01  1.28274033e-01  1.54904640e-01  8.83372143e-01\n",
      "  1.38714930e-01  1.01428183e-01  6.37514393e-02  4.74143535e-01\n",
      "  1.44318380e-01  3.32209243e-01  9.85223737e-01  1.12472244e-01\n",
      "  1.60139061e-01  2.66114644e-02 -2.41362640e-01  1.09304997e-01\n",
      "  2.65882719e-01  9.34799595e-01  6.65962224e-02 -1.44857067e-01\n",
      "  7.32175244e-01  1.01756702e+00  6.57625381e-01  6.82274953e-01\n",
      "  7.78507074e-01  3.06694232e-01  7.03120381e-01  1.47020857e-01\n",
      " -5.35194672e-02  2.63450207e-01  8.45198988e-01  2.80865752e-01\n",
      "  2.88522280e-01  7.14342083e-01  7.98068552e-01  4.05781543e-01\n",
      "  1.00941736e-01  1.92789366e-01  1.12191979e-01  8.05473642e-01\n",
      "  4.10332423e-01 -6.55145848e-04  7.89310178e-01  7.38879084e-01\n",
      "  1.43673989e-01  1.49684208e-01  1.01479914e-01  8.33962978e-01\n",
      "  8.06527571e-01  7.46997500e-02  6.54965242e-01  2.67936850e-01\n",
      "  1.17831761e-01  6.75775470e-01  2.72454182e-01  9.99158265e-01\n",
      "  5.87835137e-01  4.84754956e-01  1.70739321e-01]\n",
      "0.2615039281705948\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The predictions are in three separate numpy arrays.  Concatenate them into one.  \n",
    "# We concatenate them on axis 0, as they only have one axis.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "print(predictions)\n",
    "# Map predictions to outcomes (only possible outcomes are 1 and 0)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7878787878787877\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Initialize our algorithm\n",
    "alg = LogisticRegression(random_state=1)\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test = pandas.read_csv(\"test.csv\")\n",
    "titanic_test[\"Age\"] = titanic_test[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "titanic_test[\"Fare\"] = titanic_test[\"Fare\"].fillna(titanic_test[\"Fare\"].median())\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"male\", \"Sex\"] = 0 \n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "titanic_test[\"Embarked\"] = titanic_test[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"Q\", \"Embarked\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7856341189674523\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm with the default paramters\n",
    "# n_estimators is the number of trees we want to make\n",
    "# min_samples_split is the minimum number of rows we need to make a split\n",
    "# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, min_samples_leaf=1)\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "kf = cross_validation.KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=kf)\n",
    "\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8148148148148148\n"
     ]
    }
   ],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=100, min_samples_split=4, min_samples_leaf=2)\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "kf = cross_validation.KFold(titanic.shape[0], 3, random_state=1)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=kf)\n",
    "\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a familysize column\n",
    "titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
    "\n",
    "# The .apply method generates a new series\n",
    "titanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Col           2\n",
      "Major         2\n",
      "Mlle          2\n",
      "Sir           1\n",
      "Ms            1\n",
      "Mme           1\n",
      "Don           1\n",
      "Lady          1\n",
      "Capt          1\n",
      "Countess      1\n",
      "Jonkheer      1\n",
      "Name: Name, dtype: int64\n",
      "1     517\n",
      "2     183\n",
      "3     125\n",
      "4      40\n",
      "5       7\n",
      "6       6\n",
      "7       5\n",
      "10      3\n",
      "8       3\n",
      "9       2\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# A function to get the title from a name.\n",
    "def get_title(name):\n",
    "    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Get all the titles and print how often each one occurs.\n",
    "titles = titanic[\"Name\"].apply(get_title)\n",
    "print(pandas.value_counts(titles))\n",
    "\n",
    "# Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "\n",
    "# Verify that we converted everything.\n",
    "print(pandas.value_counts(titles))\n",
    "\n",
    "# Add in the title column.\n",
    "titanic[\"Title\"] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1b96fc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"NameLength\"]\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "# Plot the scores.  See how \"Pclass\", \"Sex\", \"Title\", and \"Fare\" are the best?\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "# Pick only the four best features.\n",
    "predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\"]\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=8, min_samples_leaf=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27946127946127947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# The algorithms we want to ensemble.\n",
    "# We're using the more linear predictors for the logistic regression, and everything with the gradient boosting classifier.\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\",]],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "# Initialize the cross validation folds\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    full_test_predictions = []\n",
    "    # Make predictions for each algorithm on each fold\n",
    "    for alg, predictors in algorithms:\n",
    "        # Fit the algorithm on the training data.\n",
    "        alg.fit(titanic[predictors].iloc[train,:], train_target)\n",
    "        # Select and predict on the test fold.  \n",
    "        # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n",
    "        test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    # Use a simple ensembling scheme -- just average the predictions to get the final classification.\n",
    "    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n",
    "    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    "\n",
    "# Put all the predictions together into one array.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Compute accuracy by comparing to the training data.\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     240\n",
      "2      79\n",
      "3      72\n",
      "4      21\n",
      "7       2\n",
      "6       2\n",
      "10      1\n",
      "5       1\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "titles = titanic_test[\"Name\"].apply(get_title)\n",
    "# We're adding the Dona title to the mapping, because it's in the test set, but not the training set\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2, \"Dona\": 10}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "titanic_test[\"Title\"] = titles\n",
    "# Check the counts of each unique title.\n",
    "print(pandas.value_counts(titanic_test[\"Title\"]))\n",
    "\n",
    "# Now, we add the family size column.\n",
    "titanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11682906, 0.47835542, 0.12614812, 0.13098152, 0.52105865,\n",
       "       0.14352087, 0.64085318, 0.18003148, 0.67801347, 0.12111117,\n",
       "       0.12105176, 0.20902103, 0.91068382, 0.10891264, 0.89142097,\n",
       "       0.87713471, 0.16349847, 0.13907786, 0.54103225, 0.55660983,\n",
       "       0.22420864, 0.53720786, 0.90572221, 0.38890591, 0.88384766,\n",
       "       0.10357312, 0.90909442, 0.13746449, 0.31046235, 0.12665715,\n",
       "       0.1166376 , 0.18274852, 0.55220981, 0.49648565, 0.42415294,\n",
       "       0.14191047, 0.50973625, 0.524522  , 0.13270502, 0.2836669 ,\n",
       "       0.11145277, 0.46618798, 0.09996496, 0.83420609, 0.89959113,\n",
       "       0.14983412, 0.31593403, 0.13789616, 0.89104179, 0.54189549,\n",
       "       0.35666363, 0.17718126, 0.83071945, 0.8799554 , 0.17559061,\n",
       "       0.13741805, 0.10667274, 0.12343846, 0.12099733, 0.91285174,\n",
       "       0.13099156, 0.15341939, 0.12993963, 0.66573198, 0.66343871,\n",
       "       0.87272599, 0.67238706, 0.28826487, 0.35236563, 0.85565528,\n",
       "       0.66224131, 0.12701989, 0.55390051, 0.36740453, 0.91110317,\n",
       "       0.41201932, 0.13014   , 0.83671261, 0.15614405, 0.66224131,\n",
       "       0.68129213, 0.2060573 , 0.20382607, 0.12105176, 0.18486624,\n",
       "       0.13130208, 0.65680528, 0.5302985 , 0.65489619, 0.79881217,\n",
       "       0.53764538, 0.12104024, 0.89137249, 0.13014   , 0.28406238,\n",
       "       0.12345362, 0.86792465, 0.14666332, 0.58599453, 0.12260777,\n",
       "       0.9043346 , 0.14730812, 0.13789616, 0.12262429, 0.62257485,\n",
       "       0.1315587 , 0.14607748, 0.13789616, 0.13020332, 0.17473028,\n",
       "       0.14286381, 0.65490305, 0.89528112, 0.67146752, 0.88346024,\n",
       "       0.13992075, 0.11805058, 0.69612517, 0.36668937, 0.86241692,\n",
       "       0.87649289, 0.12609321, 0.9027637 , 0.12099022, 0.13789616,\n",
       "       0.56971929, 0.12608177, 0.63733734, 0.13339986, 0.13340569,\n",
       "       0.12723633, 0.5160959 , 0.23921864, 0.10791691, 0.09896732,\n",
       "       0.1243112 , 0.13346489, 0.16214091, 0.52029423, 0.12232635,\n",
       "       0.20712064, 0.90529653, 0.19747943, 0.16153709, 0.42927579,\n",
       "       0.10487174, 0.33642489, 0.1351841 , 0.46618798, 0.34478747,\n",
       "       0.91431378, 0.13214993, 0.10690994, 0.48983627, 0.11274825,\n",
       "       0.12427863, 0.91070165, 0.57991621, 0.42927579, 0.51274036,\n",
       "       0.65489227, 0.57884522, 0.82113374, 0.12096643, 0.28979592,\n",
       "       0.58587099, 0.30130458, 0.14606803, 0.90250408, 0.52257368,\n",
       "       0.12101879, 0.13299492, 0.12418531, 0.13207481, 0.13196549,\n",
       "       0.87293581, 0.87633412, 0.29670316, 0.83389516, 0.85558668,\n",
       "       0.15614405, 0.33352245, 0.90219082, 0.13789616, 0.91718924,\n",
       "       0.13602993, 0.85482384, 0.12241399, 0.14217314, 0.13560677,\n",
       "       0.13488024, 0.25547174, 0.49950987, 0.12729484, 0.71980834,\n",
       "       0.10795464, 0.85516524, 0.58990442, 0.16645661, 0.53980342,\n",
       "       0.64867959, 0.6632919 , 0.60981586, 0.87333315, 0.16322631,\n",
       "       0.25696639, 0.63083508, 0.16482583, 0.88984704, 0.12346403,\n",
       "       0.12849649, 0.12097119, 0.24675036, 0.80199969, 0.41248331,\n",
       "       0.29768137, 0.65492652, 0.2186035 , 0.90027413, 0.13014   ,\n",
       "       0.81370011, 0.13611138, 0.84275389, 0.12700824, 0.87789278,\n",
       "       0.59807982, 0.12518083, 0.65489619, 0.11487488, 0.14413101,\n",
       "       0.25075172, 0.89266284, 0.11622679, 0.13791324, 0.34224635,\n",
       "       0.12796769, 0.19365851, 0.14018896, 0.80948184, 0.89790831,\n",
       "       0.87598956, 0.82598157, 0.33036565, 0.12105097, 0.33258152,\n",
       "       0.28710736, 0.87902946, 0.16058981, 0.86241692, 0.59133082,\n",
       "       0.74586496, 0.15434322, 0.39647448, 0.13354264, 0.12701859,\n",
       "       0.12101879, 0.13789616, 0.13014   , 0.83005783, 0.12700581,\n",
       "       0.1089495 , 0.12701504, 0.85003755, 0.64929877, 0.16619529,\n",
       "       0.12105176, 0.21821002, 0.12101879, 0.50973625, 0.14016477,\n",
       "       0.34495854, 0.13789616, 0.91564003, 0.63328249, 0.13207434,\n",
       "       0.85713528, 0.15861627, 0.12500109, 0.14267169, 0.16811846,\n",
       "       0.52045065, 0.66231859, 0.65489619, 0.64136781, 0.71198855,\n",
       "       0.1060108 , 0.12099022, 0.36278086, 0.13207481, 0.13014   ,\n",
       "       0.3330445 , 0.59319576, 0.13207481, 0.50584342, 0.12081671,\n",
       "       0.1226365 , 0.7790318 , 0.12665715, 0.33024477, 0.12028971,\n",
       "       0.11813952, 0.17547878, 0.12169403, 0.13347141, 0.65489619,\n",
       "       0.82133601, 0.33497542, 0.67696016, 0.20916501, 0.42575089,\n",
       "       0.13912865, 0.13799524, 0.12102117, 0.61904727, 0.90111958,\n",
       "       0.67393642, 0.23919459, 0.17328799, 0.12182849, 0.18522948,\n",
       "       0.12262429, 0.13491473, 0.16214091, 0.45541294, 0.90601339,\n",
       "       0.12509879, 0.86563777, 0.3459857 , 0.14469713, 0.17034212,\n",
       "       0.8214761 , 0.32823558, 0.13207434, 0.64322905, 0.12183258,\n",
       "       0.25111388, 0.15333416, 0.09370084, 0.20950798, 0.35411795,\n",
       "       0.17507142, 0.11812295, 0.1469565 , 0.91556472, 0.33657646,\n",
       "       0.61836794, 0.16214091, 0.62462664, 0.16542883, 0.85157874,\n",
       "       0.89603821, 0.16322631, 0.24472814, 0.16066606, 0.70031029,\n",
       "       0.15642442, 0.85672633, 0.12105018, 0.13789616, 0.57255223,\n",
       "       0.10418824, 0.87672473, 0.86918832, 0.13098152, 0.91914163,\n",
       "       0.15715004, 0.13130246, 0.53322125, 0.89562963, 0.17356044,\n",
       "       0.15319838, 0.90891502, 0.16307923, 0.13130565, 0.87654852,\n",
       "       0.90969192, 0.48853349, 0.17002319, 0.19866953, 0.13510976,\n",
       "       0.13789616, 0.14010259, 0.54133841, 0.59499235, 0.15905627,\n",
       "       0.83276876, 0.12430271, 0.12019379, 0.14606632, 0.18789785,\n",
       "       0.38579316, 0.87750054, 0.56459191, 0.1280783 , 0.1031813 ,\n",
       "       0.91169573, 0.14231518, 0.88773175, 0.12607941, 0.12971138,\n",
       "       0.90753802, 0.12635156, 0.90891637, 0.35988715, 0.30442411,\n",
       "       0.18966796, 0.15015204, 0.26822419, 0.65488934, 0.64585314,\n",
       "       0.65489619, 0.90711865, 0.56933465, 0.13014   , 0.86010063,\n",
       "       0.1012667 , 0.13014   , 0.41850305])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\"]\n",
    "\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "full_predictions = []\n",
    "for alg, predictors in algorithms:\n",
    "    # Fit the algorithm using the full training data.\n",
    "    alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    predictions = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "# The gradient boosting classifier generates better predictions, so we weight it higher.\n",
    "predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
