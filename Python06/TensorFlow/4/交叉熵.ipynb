{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "交叉熵和二次代价函数的主要区别是\n",
    "交叉熵在调整权值和偏差值时会策略比较合理，\n",
    "模型收敛的比较快\n",
    "\n",
    "将‘二次代价函数’修改为 ‘对数似然代价函数’\n",
    "\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#载入数据集\n",
    "#one_hot=true 把数据转换为0和1，把标签转换为只有0和1的格式，\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#每个批次的大小，一次放多少\n",
    "batch_size = 100\n",
    "#计算一共多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "#列是784 训练集  None 的值是根据批次来传，784是每张图片的像素点\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#创建一个简单的神经网络\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "#预测值 softmax 转化为概率值\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W)+b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0,testing Accuracy0.8258\n",
      "Iter 1,testing Accuracy0.8944\n",
      "Iter 2,testing Accuracy0.9016\n",
      "Iter 3,testing Accuracy0.9055\n",
      "Iter 4,testing Accuracy0.9088\n",
      "Iter 5,testing Accuracy0.9111\n",
      "Iter 6,testing Accuracy0.9118\n",
      "Iter 7,testing Accuracy0.9123\n",
      "Iter 8,testing Accuracy0.9153\n",
      "Iter 9,testing Accuracy0.9162\n",
      "Iter 10,testing Accuracy0.9172\n",
      "Iter 11,testing Accuracy0.9179\n",
      "Iter 12,testing Accuracy0.9182\n",
      "Iter 13,testing Accuracy0.9187\n",
      "Iter 14,testing Accuracy0.9202\n",
      "Iter 15,testing Accuracy0.9198\n",
      "Iter 16,testing Accuracy0.92\n",
      "Iter 17,testing Accuracy0.921\n",
      "Iter 18,testing Accuracy0.9211\n",
      "Iter 19,testing Accuracy0.922\n",
      "Iter 20,testing Accuracy0.9217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n以上程序还有很多地方可以优化\\n\\nLSTM 网络\\n卷积神经网络\\n\\n上述模型可以优化的内容\\n1、修改批次的大小，尝试修改\\n2、以上只用到一个输入层和一个输出层，可以增加隐藏层，\\n3、隐藏层之间的函数修改\\n4、隐藏层之间神经元也可以修改，设置，加100个神经元或者200个神经元\\n5、权值和偏差值的初始化值得修改\\n6、二次代价函数，换为交叉熵的方式\\n7、梯度下降法 修改学习率，其他的优化方式（梯度下降法）\\n8、迭代周期，21次 修改30次，200次\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#二次代价函数\n",
    "#loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "\n",
    "#对数似然代价函数、\n",
    "#labels 标签 和 logits 预测值,\n",
    "#求交叉熵的平均值\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))\n",
    "\n",
    "\n",
    "#使用梯度下降法 设置0.2的学习率 最小化loss\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#tf.equal 比较两个参数的大小是否一样，如果一样就返回true\n",
    "#tf.argmax(y,1) 求传入的Y的值最大值在哪一个位置，\n",
    "#tf.argmax(prediction,1)求预测值的最大值在哪一个位置【求最大的数字在哪一个位置 】\n",
    "#位置就是那一个标签 Y代表真实样本的值 根据标签返回值\n",
    "#测试的标签和真实的标签是否是一样的\n",
    "\n",
    "#结果存放在bool型的列表中\n",
    "#argmax 返回一维张量中最大的值所在的位置\n",
    "#将预测值和真实值做一个对比，得到判断然后存放在变量中 \n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "\n",
    "#求准确率\n",
    "#tf.cast转换类型，由于上句代码中获取的是bool值类型，现在需要转化为32float类型\n",
    "#true 变为1.0 fals为0\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "#进行训练\n",
    "with tf.Session() as sess:\n",
    "    #首先初始化变量\n",
    "    sess.run(init)\n",
    "    # 首先迭代21个周期\n",
    "    for epoch in range(21):\n",
    "        #n_batch 批次，上文中已定义\n",
    "        #执行完当前循环，代表训练完 所有的样本数据，，将所有的图片训练完毕 \n",
    "        for batch in range(n_batch):\n",
    "            #上文已定义，每个批次的大小是100\n",
    "            #获得100张图片 batch_size=100 数据保存在batch_xs里面,标签保存在batchys里面\n",
    "            #会一次按照批次去运行，去迭代数据\n",
    "            \n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            #训练，执行  获取数据，训练执行 获取数据\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "        #测试准确率 传进去测试集的标签和数据\n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"Iter \"+str(epoch)+\",testing Accuracy\"+str(acc))\n",
    "        \n",
    "'''\n",
    "以上程序还有很多地方可以优化\n",
    "\n",
    "LSTM 网络\n",
    "卷积神经网络\n",
    "\n",
    "上述模型可以优化的内容\n",
    "1、修改批次的大小，尝试修改\n",
    "2、以上只用到一个输入层和一个输出层，可以增加隐藏层，\n",
    "3、隐藏层之间的函数修改\n",
    "4、隐藏层之间神经元也可以修改，设置，加100个神经元或者200个神经元\n",
    "5、权值和偏差值的初始化值得修改\n",
    "6、二次代价函数，换为交叉熵的方式\n",
    "7、梯度下降法 修改学习率，其他的优化方式（梯度下降法）\n",
    "8、迭代周期，21次 修改30次，200次\n",
    "'''\n",
    "\n",
    "'''\n",
    "在适合的时候使用交叉熵会有助于模型的训练\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
