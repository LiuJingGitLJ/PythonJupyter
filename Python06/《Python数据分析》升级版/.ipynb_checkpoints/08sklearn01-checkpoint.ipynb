{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "基本的数学还是要掌握的\n",
    "初级阶段先没有必要系统的学习数学的理论知识\n",
    "\n",
    "\n",
    "非结构的数据的处理\n",
    "\n",
    "\n",
    "四中模型：\n",
    "分类预测，回归模型，聚类模型，时间序列\n",
    "逻辑回归LR（logisticsRegression），kmeans(聚类) 朴素贝叶斯（）\n",
    "人工神经网络（）\n",
    "逻辑回归的知识点，数学理论知识\n",
    "\n",
    "手动实现逻辑回归代码，了解算法的原理（后期要这样做）\n",
    "\n",
    "\n",
    "PCA 主成分分析 数据降维\n",
    "\n",
    "'''\n",
    "'''\n",
    "数据足够多，大数据时代\n",
    "算法的发展比较成熟\n",
    "计算机硬件设备的提高\n",
    "\n",
    "AI领域里的机器学习\n",
    "\n",
    "DeepLearning\n",
    "Deeplearning 的基础是 人工神经网络\n",
    "\n",
    "机器学习：机器学习是AI的一种，给计算机提供一种能力，这种能力不需要编程去实现\n",
    "由机器学习生成的模型自动去学习，去判断 去识别\n",
    "\n",
    "训练模型，\n",
    "\n",
    "'''\n",
    "'''\n",
    "一般分为训练集和测试集\n",
    "训练集：带有样本标签，确定当前样本中N个特征的 标签是什么\n",
    "测试集：通过已有的训练集 以及 训练集的标签，生成的模型去预测 测试集中的样本的标签\n",
    "\n",
    "把数据扔到模型里面去学习，学的是里面的参数\n",
    "\n",
    "同一个模型是不同的模型\n",
    "同一个模型 读取的数据不同，那么生成的模型也是不同的\n",
    "\n",
    "'''\n",
    "'''\n",
    "训练样本进来后，通过我们设置的参数等，然后通过第一次学习拿到预测值，\n",
    "获取到的预测值会跟真实值之间有一些差别，（因为在训练，所以会有真实值）\n",
    "预测的标签和训练集样本的标签有误差\n",
    "\n",
    "更新权重去减少误差\n",
    "把误差减少的最少的时候模型就是最好的模型\n",
    "\n",
    "'''\n",
    "'''\n",
    "机器学习的框架\n",
    "第一步：建立一堆的模型 建立一堆的函数，不同参数的组合，构成不同的模型，，\n",
    "\n",
    "第二步：定义一个度量来衡量模型的好坏，看模型预测好坏 通过 度量的 标准，然后读取数据\n",
    "\n",
    "第三部：根据标准在数据上面选一个更好方法模型或者函数出来\n",
    "\n",
    "'''\n",
    "'''\n",
    "除了算法和模型以外\n",
    "还有特征这一块\n",
    "降维\n",
    "模型筛选\n",
    "特征的预处理\n",
    "交叉验证\n",
    "'''\n",
    "'''\n",
    "监督学习 训练样本包含对应的标签，如识别问题\n",
    "\n",
    "无监督学习 训练样本不包含对应的标签 如聚类\n",
    "\n",
    "将原始数据集分为：\n",
    "\n",
    "训练集、验证集、测试集\n",
    "训练集：训练模型\n",
    "验证集：做交叉验证，选一些参数，选一些超参数，如随机森林的参数等\n",
    "由自己去定义的参数，调参，选择超参数，\n",
    "测试集：用训练好的模型去做预测，内部预测\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "训练集上训练模型，fit\n",
    "predict() 预测模型\n",
    "\n",
    "dump 保存模型\n",
    "\n",
    "维度即特征\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "#鸢尾花\n",
    "iris = datasets.load_iris()\n",
    "#手写数字识别 \n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(iris.data)\n",
    "#代表有150个样本，它的特征维度为4\n",
    "print(iris.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "#打印标签名称 三种标签，分别为\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "#将标签字符串 对应成数字\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#手写数字图片的维度\n",
    "#图片是8*8 的 用skImage读取进内存时 就是8*8的矩阵\n",
    "#标签是一维向量，没有列\n",
    "'''\n",
    "大写的X代表是一个矩阵\n",
    "小写Y代表一个向量\n",
    "\n",
    "当我们在初始化模型的的时候 手动写入的参数就是超参数，这些参数是不能通过学习得到的\n",
    "\n",
    "SVM模型在学习的时候，模型内部有很多参数要学习，这些参数让模型自动去学习就可以啦\n",
    "\n",
    "\n",
    "超参数和模型里面要学习的参数不同，\n",
    "\n",
    "训练时：让模型对象fit,fit(样本的特征，相对应的样本的标签)\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "查看结果，accuracy_score\n",
    "预测标签和真实标签\n",
    "\n",
    " \n",
    "生产环节 不可能 每次都要训练模型\n",
    "\n",
    "将模型保存下来，下次默认加载\n",
    "通过pickle 保存pickle.dump()模型\n",
    "\n",
    "with open('svm_model.pkl','wb') as f:\n",
    "    pickle.dump(svm_model,f)\n",
    "\n",
    "with open('svm_model.pkl','rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "直接预测\n",
    "后期直接通过model.predict(random_samples)\n",
    "\n",
    "\n",
    "准备数据集：\n",
    "数据处理，特征工程，训练集、测试集分割\n",
    "\n",
    "特征工程 不同行业领域的特征都不同，比较复杂\n",
    "\n",
    "文本数据分析\n",
    "\n",
    "100维特征中：哪些是好的，哪些是不好，是否有冗余的\n",
    "\n",
    "PCA：\n",
    "\n",
    "\n",
    "生产环境中不太可能去重新生成模型，在模型中去调整超参数\n",
    "\n",
    "如何调整超参数？\n",
    "1、根据经验调整超参数\n",
    "2、通过交叉验证调整最优参数\n",
    "\n",
    "行数为样本数\n",
    "列数是特征维度\n",
    "\n",
    "首先进行数据处理\n",
    "二位数组：形状（样本数，特征维度）\n",
    "\n",
    "np.reshape()转化数据集维度\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "特征归一化\n",
    "平米数/2000\n",
    "特征归一化之后 效果 会特别好，学习时间变短，模型的效果也比较好\n",
    "\n",
    "为什么要进行特征归一化：\n",
    "1、引入归一化，是由于在不同评价指标（特征指标）中，其量纲或是量纲单位往往不同，\n",
    "变化区间处于不同的数量级，若不进行归一化，可能导致某些指标被忽视，影响到数据分析的结果。\n",
    "\n",
    "2、为了消除特征数据之间的量纲影响，需要进行归一化处理，以解决特征指标之间的可比性。\n",
    "原始数据经过归一化处理后，各指标处于同一数量级，以便进行综合对比评价。\n",
    "\n",
    "例：\n",
    "房间的平米数：70 80 100\n",
    "房间的卧室个数：2 3 4\n",
    "卧室和房间比例向\n",
    "如果不做任何的处理，扰动就比较大，训练学习的时间比较长，模型的效果也不好\n",
    "\n",
    "此时要把特征归一化进同一个区域，归一化到[0,1]\n",
    "结果是学习时间变短，模型效果也比较好\n",
    "\n",
    "#######################\n",
    "梯度下降，损失值越小\n",
    "\n",
    "Python进行不平衡数据处理\n",
    "\n",
    "特征归一化不是对样本，是对一列操作的\n",
    "一行中样本有不同的特征，一列是特征\n",
    "特征归一化是对一列\n",
    "\n",
    "先向量化特征还是应该先筛选变量？\n",
    "没有规定的步骤\n",
    "先向量化，去做筛选\n",
    "\n",
    "一定要把数据转换为numpy数组\n",
    "random_state 确保每次随机分割得到相同的结果\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=1/3,random_state=7)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "'''\n",
    "归一化：\n",
    "preprocessing.scale(X)\n",
    "preprocessing 有中心归一化，最大最小归一化\n",
    "\n",
    "特征的维度没有变化，只是范围改变，只是在范围上进行了缩放\n",
    "'''\n",
    "'''\n",
    "\n",
    "X,y =make_classification()\n",
    "\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "svm_classifier.score(X_test,y_test)\n",
    "\n",
    "特征归一化很有必要，提升模型的预测度，由50% 提升至90%\n",
    "'''\n",
    "'''\n",
    "样本数大于50\n",
    "是否预测一个类？类上面是否有标签？（有监督学习还是无监督学习）\n",
    "若数量小于100K 使用线性SVC，大于100k 使用随机梯度下降\n",
    "文本数据使用朴素贝叶斯，非文本数据使用K近邻\n",
    "或者在使用随机森林\n",
    "\n",
    "\n",
    "\n",
    "聚类模型：\n",
    "Kmeans：\n",
    "GMM（高斯混合模型）：\n",
    "\n",
    "\n",
    "Regression\n",
    "\n",
    "PCA 数据降维（主成分分析）\n",
    "'''\n",
    "'''\n",
    "训练的对象：\n",
    "Estimator 对象\n",
    "\n",
    "fit方法训练Estimator\n",
    "get_params() 返回模型之前定义的参数\n",
    "score() 对 Estimator进行评分\n",
    "回归模型：使用 决定系数 评分\n",
    "分类模型：使用 准确率 评分\n",
    "'''\n",
    "'''\n",
    "连续的标签 要使用 回归模型\n",
    "\n",
    "获取数据集=特征处理完毕之后\n",
    "-------\n",
    "1、初始化模型\n",
    "2、数据集进行拆分（分割数据集，测试集）\n",
    "3、训练模型 .fit(X_train, y_train )\n",
    "模型训练完毕之后，使用模型.get_params()//获取参数\n",
    "#返回参数\n",
    "lr_model.get_params()返回参数\n",
    "#训练集上的预测\n",
    "lr_model.score(X_train, y_train)\n",
    "#0.7596\n",
    "#测试集上的预测\n",
    "lr_model.score(X_test, y_test)\n",
    "#0.6698\n",
    "'''\n",
    "\n",
    "'''\n",
    "交叉验证调整参数、调整超参数\n",
    "cross valation (CV)\n",
    "在训练集中进行交叉验证\n",
    "10折的交叉验证\n",
    "\n",
    "C = 1 的时候做10轮\n",
    "将训练集分为10等分\n",
    "拿出第1份当做验证集，剩余9份做验证\n",
    "拿出第2份当做验证集，剩余9份做验证\n",
    "拿出第3份当做验证集，剩余9份做验证\n",
    "拿出第...份当做验证集，剩余9份做验证\n",
    "\n",
    "交叉完毕之后，拿到10次验证获取到的值得平均值\n",
    "\n",
    "C = 2 的时候再做10轮\n",
    "....\n",
    "C = 10 的时候在做10轮\n",
    "\n",
    "使用K近邻的例子演示交叉验证的方式\n",
    "\n",
    "01：35：14\n",
    "'''\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
